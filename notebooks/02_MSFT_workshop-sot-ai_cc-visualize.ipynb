{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2OJtDt541b3"
      },
      "source": [
        "# Workshop Microsoft - Sostenibilidad\n",
        "En el siguiente ejemplo analizaremos el coste energético de un modelo de la inferencia del modelo Phi de Microsoft.\n",
        "Se puede realizar este ejemplo con CPU o GPU. En caso de ser con GPU es necesario indicarlo en los parámetros de configuración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1739966605365
        },
        "id": "0LyAUyQ4s3_7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import pipeline\n",
        "import textwrap\n",
        "from codecarbon import EmissionsTracker\n",
        "from codecarbon import track_emissions\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parametros de configuración\n",
        "model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "output_dir_emissions_track=\"/home/azureuser/cloudfiles/code/Users/paul.vanb/worshop-ia-sostenible/outputs\"\n",
        "device=\"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def wrap_text(text, width=100):\n",
        "    \"\"\"\n",
        "    Envuelve el texto dado para que cada línea no supere el ancho especificado.\n",
        "    \n",
        "    Args:\n",
        "        text (str): El texto de entrada.\n",
        "        width (int): El ancho máximo de cada línea (por defecto, 100 caracteres).\n",
        "    \n",
        "    Returns:\n",
        "        str: Texto con saltos de línea insertados para cumplir con el ancho especificado.\n",
        "    \"\"\"\n",
        "    lines = text.split('\\n')  # Divide el texto en líneas basadas en saltos de línea existentes.\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]  # Envuelve cada línea individualmente.\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)  # Une las líneas envueltas con saltos de línea.\n",
        "    return wrapped_text\n",
        "\n",
        "def generate(input_text, system_prompt=\"\", max_length=1024):\n",
        "    \"\"\"\n",
        "    Genera una respuesta basada en el texto de entrada utilizando un modelo de IA.\n",
        "    \n",
        "    Args:\n",
        "        input_text (str): Texto de entrada del usuario.\n",
        "        system_prompt (str): Mensaje de sistema opcional para guiar la respuesta del modelo.\n",
        "        max_length (int): Longitud máxima de la respuesta generada (por defecto, 1024 caracteres).\n",
        "    \n",
        "    Returns:\n",
        "        str: Texto generado y formateado con saltos de línea adecuados.\n",
        "    \"\"\"\n",
        "    # Si no se proporciona un mensaje del sistema, se usa un mensaje por defecto.\n",
        "    if system_prompt != \"\":\n",
        "        system_prompt = system_prompt\n",
        "    else:\n",
        "        system_prompt = \"You are a friendly and helpful assistant\"\n",
        "    \n",
        "    # Construcción del historial de mensajes con el mensaje del sistema y la entrada del usuario.\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": input_text},\n",
        "    ]\n",
        "    \n",
        "    # Generación de la respuesta del modelo.\n",
        "    output = pipe(messages, **generation_args)\n",
        "    text = output[0]['generated_text']  # Obtiene el texto generado.\n",
        "    \n",
        "    # Envuelve el texto generado para cumplir con el ancho especificado.\n",
        "    wrapped_text = wrap_text(text)\n",
        "    return wrapped_text\n",
        "\n",
        "@track_emissions(project_name=\"workshop-sostenibilidad\", output_dir=output_dir_emissions_track,\n",
        "                 cloud_provider=\"azure\", cloud_region=\"North Europe\", pue=1.19)\n",
        "def answer_to_different_messages(messages):\n",
        "    \"\"\"\n",
        "    Procesa una lista de mensajes y genera respuestas mientras realiza un seguimiento de las emisiones.\n",
        "    \n",
        "    Args:\n",
        "        messages (list): Lista de mensajes de entrada.\n",
        "    \n",
        "    Returns:\n",
        "        list: Lista de respuestas generadas junto con los mensajes de entrada y sus identificadores.\n",
        "    \"\"\"\n",
        "    outputs = []  # Lista para almacenar los resultados.\n",
        "    system_prompt = \"Eres un asistente de Microsoft experto en sostenibilidad llamado SostAI\"  # Mensaje del sistema.\n",
        "    \n",
        "    # Itera sobre cada mensaje y genera una respuesta.\n",
        "    for mid, message in enumerate(messages):\n",
        "        output = generate(message, system_prompt=system_prompt)  # Genera la respuesta.\n",
        "        outputs.append([mid, message, output])  # Almacena el identificador, mensaje y respuesta.\n",
        "    \n",
        "    return outputs  # Devuelve la lista de respuestas generadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1739966892343
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>project_name</th>\n",
              "      <th>run_id</th>\n",
              "      <th>experiment_id</th>\n",
              "      <th>duration</th>\n",
              "      <th>emissions</th>\n",
              "      <th>emissions_rate</th>\n",
              "      <th>cpu_power</th>\n",
              "      <th>gpu_power</th>\n",
              "      <th>ram_power</th>\n",
              "      <th>...</th>\n",
              "      <th>cpu_count</th>\n",
              "      <th>cpu_model</th>\n",
              "      <th>gpu_count</th>\n",
              "      <th>gpu_model</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>ram_total_size</th>\n",
              "      <th>tracking_mode</th>\n",
              "      <th>on_cloud</th>\n",
              "      <th>pue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-02-19T12:02:50</td>\n",
              "      <td>codecarbon</td>\n",
              "      <td>3bfd136c-d8e5-4f4e-a98e-a51239239023</td>\n",
              "      <td>5b0fa12a-3dd7-45bb-9766-cc326314d9f1</td>\n",
              "      <td>17.135990</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>97.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.091317</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-122.3303</td>\n",
              "      <td>47.6109</td>\n",
              "      <td>31.343273</td>\n",
              "      <td>process</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-02-19T12:03:10</td>\n",
              "      <td>codecarbon</td>\n",
              "      <td>9bc68c95-44f7-4838-9b5e-00de148b7f57</td>\n",
              "      <td>5b0fa12a-3dd7-45bb-9766-cc326314d9f1</td>\n",
              "      <td>17.254767</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>97.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.753727</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-122.3303</td>\n",
              "      <td>47.6109</td>\n",
              "      <td>31.343273</td>\n",
              "      <td>machine</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-02-19T12:04:54</td>\n",
              "      <td>workshop-sostenibilidad</td>\n",
              "      <td>ef6ae2a3-bd22-469f-aa2e-e12b329f5886</td>\n",
              "      <td>5b0fa12a-3dd7-45bb-9766-cc326314d9f1</td>\n",
              "      <td>63.112533</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>97.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.753727</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-122.3303</td>\n",
              "      <td>47.6109</td>\n",
              "      <td>31.343273</td>\n",
              "      <td>machine</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-02-19T15:49:45</td>\n",
              "      <td>codecarbon</td>\n",
              "      <td>c29eaeff-7e73-4de2-81f5-2d7d7e121a0f</td>\n",
              "      <td>D08fa668-aed9-4ee9-a535-dedb1361039c</td>\n",
              "      <td>20.548237</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>97.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.047070</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-122.3303</td>\n",
              "      <td>47.6109</td>\n",
              "      <td>31.343277</td>\n",
              "      <td>process</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-02-23T09:48:15</td>\n",
              "      <td>codecarbon</td>\n",
              "      <td>d50c6d8e-a5bd-46a7-8b1d-18e21a2c39b1</td>\n",
              "      <td>D08fa668-aed9-4ee9-a535-dedb1361039c</td>\n",
              "      <td>29.065790</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>97.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.061984</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-122.3303</td>\n",
              "      <td>47.6109</td>\n",
              "      <td>31.343277</td>\n",
              "      <td>process</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             timestamp             project_name  \\\n",
              "0  2025-02-19T12:02:50               codecarbon   \n",
              "1  2025-02-19T12:03:10               codecarbon   \n",
              "2  2025-02-19T12:04:54  workshop-sostenibilidad   \n",
              "3  2025-02-19T15:49:45               codecarbon   \n",
              "4  2025-02-23T09:48:15               codecarbon   \n",
              "\n",
              "                                 run_id                         experiment_id  \\\n",
              "0  3bfd136c-d8e5-4f4e-a98e-a51239239023  5b0fa12a-3dd7-45bb-9766-cc326314d9f1   \n",
              "1  9bc68c95-44f7-4838-9b5e-00de148b7f57  5b0fa12a-3dd7-45bb-9766-cc326314d9f1   \n",
              "2  ef6ae2a3-bd22-469f-aa2e-e12b329f5886  5b0fa12a-3dd7-45bb-9766-cc326314d9f1   \n",
              "3  c29eaeff-7e73-4de2-81f5-2d7d7e121a0f  D08fa668-aed9-4ee9-a535-dedb1361039c   \n",
              "4  d50c6d8e-a5bd-46a7-8b1d-18e21a2c39b1  D08fa668-aed9-4ee9-a535-dedb1361039c   \n",
              "\n",
              "    duration  emissions  emissions_rate  cpu_power  gpu_power  ram_power  ...  \\\n",
              "0  17.135990   0.000041        0.000002       97.5        0.0   3.091317  ...   \n",
              "1  17.254767   0.000044        0.000003       97.5        0.0  11.753727  ...   \n",
              "2  63.112533   0.000162        0.000003       97.5        0.0  11.753727  ...   \n",
              "3  20.548237   0.000049        0.000002       97.5        0.0   3.047070  ...   \n",
              "4  29.065790   0.000069        0.000002       97.5        0.0   3.061984  ...   \n",
              "\n",
              "   cpu_count                                       cpu_model  gpu_count  \\\n",
              "0          4  Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz        NaN   \n",
              "1          4  Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz        NaN   \n",
              "2          4  Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz        NaN   \n",
              "3          4  Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz        NaN   \n",
              "4          4  Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz        NaN   \n",
              "\n",
              "   gpu_model longitude latitude ram_total_size  tracking_mode  on_cloud  pue  \n",
              "0        NaN -122.3303  47.6109      31.343273        process         N  1.0  \n",
              "1        NaN -122.3303  47.6109      31.343273        machine         N  1.0  \n",
              "2        NaN -122.3303  47.6109      31.343273        machine         N  1.0  \n",
              "3        NaN -122.3303  47.6109      31.343277        process         N  1.0  \n",
              "4        NaN -122.3303  47.6109      31.343277        process         N  1.0  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_emissions = pd.read_csv(os.path.join(output_dir_emissions_track,os.path.join(output_dir_emissions_track,\"emissions.csv\")))\n",
        "df_emissions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Uso del dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#carbonboard --filepath=os.path.join(output_dir_emissions_track,\"emissions.csv\") --port=3333"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU5UVLwy4yGh"
      },
      "source": [
        "# Uso de la API\n",
        "\n",
        "https://dashboard.codecarbon.io/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvR0gxrO9Dta",
        "outputId": "c766c678-0056-490e-ed4e-b7bb00641f64"
      },
      "outputs": [],
      "source": [
        "# en local\n",
        "#!codecarbon login\n",
        "#!codecarbon config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/works-sost-cpu/code'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODECARBON_API_KEY = os.environ[\"CODECARBON_API_KEY\"]\n",
        "CODECARBON_EXPERIMENT_ID = os.environ[\"CODECARBON_EXPERIMENT_ID\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xG0X4Rg8hym",
        "outputId": "aa154879-5fdf-4db8-e11d-8c8b96c90859"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 17:39:09] Codecarbon is taking the configuration from global file: /home/azureuser/.codecarbon.config\n",
            "[codecarbon INFO @ 17:39:10] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 17:39:10] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 17:39:10] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 17:39:11] CPU Model on constant consumption mode: Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\n",
            "[codecarbon INFO @ 17:39:11] [setup] GPU Tracking...\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[codecarbon INFO @ 17:39:11] No GPU found.\n",
            "[codecarbon INFO @ 17:39:11] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 17:39:11]   Platform system: Linux-5.15.0-1073-azure-x86_64-with-glibc2.31\n",
            "[codecarbon INFO @ 17:39:11]   Python version: 3.10.14\n",
            "[codecarbon INFO @ 17:39:11]   CodeCarbon version: 2.8.3\n",
            "[codecarbon INFO @ 17:39:11]   Available RAM : 31.343 GB\n",
            "[codecarbon INFO @ 17:39:11]   CPU count: 4\n",
            "[codecarbon INFO @ 17:39:11]   CPU model: Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\n",
            "[codecarbon INFO @ 17:39:11]   GPU count: None\n",
            "[codecarbon INFO @ 17:39:11]   GPU model: None\n",
            "[codecarbon WARNING @ 17:39:11] Cloud provider 'azure' do not publish electricity carbon intensity. Using country value instead.\n",
            "[codecarbon INFO @ 17:39:11] Saving emissions data to file /home/azureuser/cloudfiles/code/Users/paul.vanb/worshop-ia-sostenible/outputs/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon ERROR @ 17:39:12] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-23T17:39:11.687535+00:00\", \"experiment_id\": \"D08fa668-aed9-4ee9-a535-dedb1361039c\", \"os\": \"Linux-5.15.0-1073-azure-x86_64-with-glibc2.31\", \"python_version\": \"3.10.14\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 4, \"cpu_model\": \"Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\", \"gpu_count\": null, \"gpu_model\": null, \"longitude\": -122.3, \"latitude\": 47.6, \"region\": null, \"provider\": null, \"ram_total_size\": 31.343276977539062, \"tracking_mode\": \"process\"}\n",
            "[codecarbon ERROR @ 17:39:12] ApiClient API return http code 403 and answer : {\"detail\":\"Not allowed to perform this action\"}\n",
            "[codecarbon INFO @ 17:39:24] Energy consumed for RAM : 0.000077 kWh. RAM Power : 3.093413829803467 W\n",
            "[codecarbon INFO @ 17:39:24] Energy consumed for all CPUs : 0.002438 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:39:24] 0.002515 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:39:27] Energy consumed for RAM : 0.000013 kWh. RAM Power : 3.0934195518493652 W\n",
            "[codecarbon INFO @ 17:39:27] Energy consumed for all CPUs : 0.000407 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:39:27] 0.000420 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:39:34] Energy consumed for RAM : 0.000019 kWh. RAM Power : 3.0934195518493652 W\n",
            "[codecarbon INFO @ 17:39:34] Energy consumed for all CPUs : 0.000606 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:39:34] 0.000625 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon ERROR @ 17:39:37] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-23T17:39:37.091444+00:00\", \"experiment_id\": \"D08fa668-aed9-4ee9-a535-dedb1361039c\", \"os\": \"Linux-5.15.0-1073-azure-x86_64-with-glibc2.31\", \"python_version\": \"3.10.14\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 4, \"cpu_model\": \"Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\", \"gpu_count\": null, \"gpu_model\": null, \"longitude\": -122.3, \"latitude\": 47.6, \"region\": null, \"provider\": null, \"ram_total_size\": 31.343276977539062, \"tracking_mode\": \"process\"}\n",
            "[codecarbon ERROR @ 17:39:37] ApiClient API return http code 403 and answer : {\"detail\":\"Not allowed to perform this action\"}\n",
            "[codecarbon ERROR @ 17:39:37] ApiClient.add_emission still no run_id, aborting for this time !\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 44.7 s, sys: 89.5 ms, total: 44.8 s\n",
            "Wall time: 27.9 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 17:39:39] Energy consumed for RAM : 0.000090 kWh. RAM Power : 3.093545436859131 W\n",
            "[codecarbon INFO @ 17:39:39] Energy consumed for all CPUs : 0.002844 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:39:39] 0.002934 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:39:54] Energy consumed for RAM : 0.000103 kWh. RAM Power : 3.093595504760742 W\n",
            "[codecarbon INFO @ 17:39:54] Energy consumed for all CPUs : 0.003250 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:39:54] 0.003353 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:39:54] 0.002368 g.CO2eq/s mean an estimation of 74.67278125045584 kg.CO2eq/year\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon ERROR @ 17:39:54] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-23T17:39:54.256916+00:00\", \"experiment_id\": \"D08fa668-aed9-4ee9-a535-dedb1361039c\", \"os\": \"Linux-5.15.0-1073-azure-x86_64-with-glibc2.31\", \"python_version\": \"3.10.14\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 4, \"cpu_model\": \"Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\", \"gpu_count\": null, \"gpu_model\": null, \"longitude\": -122.3, \"latitude\": 47.6, \"region\": null, \"provider\": null, \"ram_total_size\": 31.343276977539062, \"tracking_mode\": \"process\"}\n",
            "[codecarbon ERROR @ 17:39:54] ApiClient API return http code 403 and answer : {\"detail\":\"Not allowed to perform this action\"}\n",
            "[codecarbon ERROR @ 17:39:54] ApiClient.add_emission still no run_id, aborting for this time !\n",
            "[codecarbon INFO @ 17:40:09] Energy consumed for RAM : 0.000116 kWh. RAM Power : 3.0936012268066406 W\n",
            "[codecarbon INFO @ 17:40:09] Energy consumed for all CPUs : 0.003656 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:40:09] 0.003772 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:40:24] Energy consumed for RAM : 0.000129 kWh. RAM Power : 3.0936098098754883 W\n",
            "[codecarbon INFO @ 17:40:24] Energy consumed for all CPUs : 0.004063 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:40:24] 0.004191 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:40:39] Energy consumed for RAM : 0.000142 kWh. RAM Power : 3.093611240386963 W\n",
            "[codecarbon INFO @ 17:40:39] Energy consumed for all CPUs : 0.004469 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:40:39] 0.004610 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:40:54] Energy consumed for RAM : 0.000155 kWh. RAM Power : 3.093614101409912 W\n",
            "[codecarbon INFO @ 17:40:54] Energy consumed for all CPUs : 0.004875 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:40:54] 0.005030 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:41:09] Energy consumed for RAM : 0.000167 kWh. RAM Power : 3.093614101409912 W\n",
            "[codecarbon INFO @ 17:41:09] Energy consumed for all CPUs : 0.005281 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:41:09] 0.005449 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:41:24] Energy consumed for RAM : 0.000180 kWh. RAM Power : 3.093618392944336 W\n",
            "[codecarbon INFO @ 17:41:24] Energy consumed for all CPUs : 0.005687 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:41:24] 0.005868 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:41:39] Energy consumed for RAM : 0.000193 kWh. RAM Power : 3.0953993797302246 W\n",
            "[codecarbon INFO @ 17:41:39] Energy consumed for all CPUs : 0.006094 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:41:39] 0.006287 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:41:54] Energy consumed for RAM : 0.000206 kWh. RAM Power : 3.0960702896118164 W\n",
            "[codecarbon INFO @ 17:41:54] Energy consumed for all CPUs : 0.006500 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:41:54] 0.006706 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:41:54] 0.002368 g.CO2eq/s mean an estimation of 74.67554658712537 kg.CO2eq/year\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon ERROR @ 17:41:54] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-23T17:41:54.261122+00:00\", \"experiment_id\": \"D08fa668-aed9-4ee9-a535-dedb1361039c\", \"os\": \"Linux-5.15.0-1073-azure-x86_64-with-glibc2.31\", \"python_version\": \"3.10.14\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 4, \"cpu_model\": \"Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\", \"gpu_count\": null, \"gpu_model\": null, \"longitude\": -122.3, \"latitude\": 47.6, \"region\": null, \"provider\": null, \"ram_total_size\": 31.343276977539062, \"tracking_mode\": \"process\"}\n",
            "[codecarbon ERROR @ 17:41:54] ApiClient API return http code 403 and answer : {\"detail\":\"Not allowed to perform this action\"}\n",
            "[codecarbon ERROR @ 17:41:54] ApiClient.add_emission still no run_id, aborting for this time !\n",
            "[codecarbon INFO @ 17:42:09] Energy consumed for RAM : 0.000219 kWh. RAM Power : 3.096076011657715 W\n",
            "[codecarbon INFO @ 17:42:09] Energy consumed for all CPUs : 0.006906 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:42:09] 0.007125 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:42:24] Energy consumed for RAM : 0.000232 kWh. RAM Power : 3.0965309143066406 W\n",
            "[codecarbon INFO @ 17:42:24] Energy consumed for all CPUs : 0.007312 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:42:24] 0.007544 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:42:39] Energy consumed for RAM : 0.000245 kWh. RAM Power : 3.096086025238037 W\n",
            "[codecarbon INFO @ 17:42:39] Energy consumed for all CPUs : 0.007719 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:42:39] 0.007963 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:42:54] Energy consumed for RAM : 0.000258 kWh. RAM Power : 3.096086025238037 W\n",
            "[codecarbon INFO @ 17:42:54] Energy consumed for all CPUs : 0.008125 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:42:54] 0.008382 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:43:09] Energy consumed for RAM : 0.000271 kWh. RAM Power : 3.096466541290283 W\n",
            "[codecarbon INFO @ 17:43:09] Energy consumed for all CPUs : 0.008531 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:43:09] 0.008802 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:43:24] Energy consumed for RAM : 0.000283 kWh. RAM Power : 3.096470832824707 W\n",
            "[codecarbon INFO @ 17:43:24] Energy consumed for all CPUs : 0.008937 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:43:24] 0.009221 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:43:39] Energy consumed for RAM : 0.000296 kWh. RAM Power : 3.096483707427979 W\n",
            "[codecarbon INFO @ 17:43:39] Energy consumed for all CPUs : 0.009343 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:43:39] 0.009640 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:43:54] Energy consumed for RAM : 0.000309 kWh. RAM Power : 3.096621036529541 W\n",
            "[codecarbon INFO @ 17:43:54] Energy consumed for all CPUs : 0.009750 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:43:54] 0.010059 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:43:54] 0.002368 g.CO2eq/s mean an estimation of 74.67621658978918 kg.CO2eq/year\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon ERROR @ 17:43:54] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-23T17:43:54.264744+00:00\", \"experiment_id\": \"D08fa668-aed9-4ee9-a535-dedb1361039c\", \"os\": \"Linux-5.15.0-1073-azure-x86_64-with-glibc2.31\", \"python_version\": \"3.10.14\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 4, \"cpu_model\": \"Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\", \"gpu_count\": null, \"gpu_model\": null, \"longitude\": -122.3, \"latitude\": 47.6, \"region\": null, \"provider\": null, \"ram_total_size\": 31.343276977539062, \"tracking_mode\": \"process\"}\n",
            "[codecarbon ERROR @ 17:43:54] ApiClient API return http code 403 and answer : {\"detail\":\"Not allowed to perform this action\"}\n",
            "[codecarbon ERROR @ 17:43:54] ApiClient.add_emission still no run_id, aborting for this time !\n",
            "[codecarbon INFO @ 17:44:09] Energy consumed for RAM : 0.000322 kWh. RAM Power : 3.0967140197753906 W\n",
            "[codecarbon INFO @ 17:44:09] Energy consumed for all CPUs : 0.010156 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:44:09] 0.010478 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:44:24] Energy consumed for RAM : 0.000335 kWh. RAM Power : 3.0968055725097656 W\n",
            "[codecarbon INFO @ 17:44:24] Energy consumed for all CPUs : 0.010562 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:44:24] 0.010897 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:44:39] Energy consumed for RAM : 0.000348 kWh. RAM Power : 3.0968055725097656 W\n",
            "[codecarbon INFO @ 17:44:39] Energy consumed for all CPUs : 0.010968 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:44:39] 0.011316 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:44:54] Energy consumed for RAM : 0.000361 kWh. RAM Power : 3.0968055725097656 W\n",
            "[codecarbon INFO @ 17:44:54] Energy consumed for all CPUs : 0.011375 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:44:54] 0.011735 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:45:09] Energy consumed for RAM : 0.000374 kWh. RAM Power : 3.0968055725097656 W\n",
            "[codecarbon INFO @ 17:45:09] Energy consumed for all CPUs : 0.011781 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:45:09] 0.012155 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:45:24] Energy consumed for RAM : 0.000387 kWh. RAM Power : 3.096874237060547 W\n",
            "[codecarbon INFO @ 17:45:24] Energy consumed for all CPUs : 0.012187 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:45:24] 0.012574 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:45:39] Energy consumed for RAM : 0.000399 kWh. RAM Power : 3.096892833709717 W\n",
            "[codecarbon INFO @ 17:45:39] Energy consumed for all CPUs : 0.012593 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:45:39] 0.012993 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:45:54] Energy consumed for RAM : 0.000412 kWh. RAM Power : 3.096892833709717 W\n",
            "[codecarbon INFO @ 17:45:54] Energy consumed for all CPUs : 0.012999 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:45:54] 0.013412 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:45:54] 0.002368 g.CO2eq/s mean an estimation of 74.67677114984383 kg.CO2eq/year\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon ERROR @ 17:45:54] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-23T17:45:54.267778+00:00\", \"experiment_id\": \"D08fa668-aed9-4ee9-a535-dedb1361039c\", \"os\": \"Linux-5.15.0-1073-azure-x86_64-with-glibc2.31\", \"python_version\": \"3.10.14\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 4, \"cpu_model\": \"Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\", \"gpu_count\": null, \"gpu_model\": null, \"longitude\": -122.3, \"latitude\": 47.6, \"region\": null, \"provider\": null, \"ram_total_size\": 31.343276977539062, \"tracking_mode\": \"process\"}\n",
            "[codecarbon ERROR @ 17:45:54] ApiClient API return http code 403 and answer : {\"detail\":\"Not allowed to perform this action\"}\n",
            "[codecarbon ERROR @ 17:45:54] ApiClient.add_emission still no run_id, aborting for this time !\n",
            "[codecarbon INFO @ 17:46:09] Energy consumed for RAM : 0.000425 kWh. RAM Power : 3.096892833709717 W\n",
            "[codecarbon INFO @ 17:46:09] Energy consumed for all CPUs : 0.013406 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:46:09] 0.013831 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:46:24] Energy consumed for RAM : 0.000438 kWh. RAM Power : 3.097466468811035 W\n",
            "[codecarbon INFO @ 17:46:24] Energy consumed for all CPUs : 0.013812 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:46:24] 0.014250 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:46:39] Energy consumed for RAM : 0.000451 kWh. RAM Power : 3.097466468811035 W\n",
            "[codecarbon INFO @ 17:46:39] Energy consumed for all CPUs : 0.014218 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:46:39] 0.014669 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:46:54] Energy consumed for RAM : 0.000464 kWh. RAM Power : 3.097466468811035 W\n",
            "[codecarbon INFO @ 17:46:54] Energy consumed for all CPUs : 0.014624 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:46:54] 0.015088 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:47:09] Energy consumed for RAM : 0.000477 kWh. RAM Power : 3.097466468811035 W\n",
            "[codecarbon INFO @ 17:47:09] Energy consumed for all CPUs : 0.015031 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:47:09] 0.015508 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:47:24] Energy consumed for RAM : 0.000490 kWh. RAM Power : 3.0974678993225098 W\n",
            "[codecarbon INFO @ 17:47:24] Energy consumed for all CPUs : 0.015437 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:47:24] 0.015927 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:47:39] Energy consumed for RAM : 0.000503 kWh. RAM Power : 3.0974678993225098 W\n",
            "[codecarbon INFO @ 17:47:39] Energy consumed for all CPUs : 0.015843 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:47:39] 0.016346 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:47:54] Energy consumed for RAM : 0.000516 kWh. RAM Power : 3.0974678993225098 W\n",
            "[codecarbon INFO @ 17:47:54] Energy consumed for all CPUs : 0.016249 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:47:54] 0.016765 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:47:54] 0.002368 g.CO2eq/s mean an estimation of 74.67785909408401 kg.CO2eq/year\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon ERROR @ 17:47:55] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-23T17:47:54.270815+00:00\", \"experiment_id\": \"D08fa668-aed9-4ee9-a535-dedb1361039c\", \"os\": \"Linux-5.15.0-1073-azure-x86_64-with-glibc2.31\", \"python_version\": \"3.10.14\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 4, \"cpu_model\": \"Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\", \"gpu_count\": null, \"gpu_model\": null, \"longitude\": -122.3, \"latitude\": 47.6, \"region\": null, \"provider\": null, \"ram_total_size\": 31.343276977539062, \"tracking_mode\": \"process\"}\n",
            "[codecarbon ERROR @ 17:47:55] ApiClient API return http code 403 and answer : {\"detail\":\"Not allowed to perform this action\"}\n",
            "[codecarbon ERROR @ 17:47:55] ApiClient.add_emission still no run_id, aborting for this time !\n",
            "[codecarbon INFO @ 17:48:09] Energy consumed for RAM : 0.000528 kWh. RAM Power : 3.097469329833985 W\n",
            "[codecarbon INFO @ 17:48:09] Energy consumed for all CPUs : 0.016656 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:48:09] 0.017184 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 17:48:24] Energy consumed for RAM : 0.000541 kWh. RAM Power : 3.097469329833985 W\n",
            "[codecarbon INFO @ 17:48:24] Energy consumed for all CPUs : 0.017062 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:48:24] 0.017603 kWh of electricity used since the beginning.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%time\n",
        "# Start tracking\n",
        "tracker = EmissionsTracker(tracking_mode=\"process\", save_to_api=True,api_key= CODECARBON_API_KEY,\n",
        "                           output_dir=output_dir_emissions_track,\n",
        "                 )\n",
        "tracker.start()\n",
        "\n",
        "generate('¿Quién eres?',\n",
        "         system_prompt=\"Eres un asistente majo\",\n",
        "         )\n",
        "emmissions = tracker.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROD1radl8jfp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e980c20fece4573a9a522f1e5d84e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcef54490bae4d83b6ef6d36bbf46d84",
              "IPY_MODEL_1ed491b9ba624120bc6b3e6db5b98cf6",
              "IPY_MODEL_102b824d816e43259751e828e46a2566"
            ],
            "layout": "IPY_MODEL_51921656a92c437e82dc96a0d14246e3"
          }
        },
        "102b824d816e43259751e828e46a2566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2523f8c0d6274cdd977884b215f516a3",
            "placeholder": "​",
            "style": "IPY_MODEL_fb068428db9148efbf737dbff9e01867",
            "value": " 2/2 [00:37&lt;00:00, 17.82s/it]"
          }
        },
        "11dec34858fe493ba356c42e98dec0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ed491b9ba624120bc6b3e6db5b98cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7240007e78444219878b593e7b49a93a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd317caff4c8479fa02a4403361e2463",
            "value": 2
          }
        },
        "2523f8c0d6274cdd977884b215f516a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51921656a92c437e82dc96a0d14246e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7240007e78444219878b593e7b49a93a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b715b9944fa547a4b65e554dc5d9fd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd317caff4c8479fa02a4403361e2463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb068428db9148efbf737dbff9e01867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcef54490bae4d83b6ef6d36bbf46d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b715b9944fa547a4b65e554dc5d9fd1e",
            "placeholder": "​",
            "style": "IPY_MODEL_11dec34858fe493ba356c42e98dec0c7",
            "value": "Loading checkpoint shards: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
