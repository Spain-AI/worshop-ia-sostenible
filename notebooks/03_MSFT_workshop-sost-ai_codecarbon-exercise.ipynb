{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2OJtDt541b3"
      },
      "source": [
        "# Workshop Microsoft - Sostenibilidad\n",
        "En el siguiente ejemplo analizaremos el coste energético de un modelo de la inferencia del modelo Phi de Microsoft.\n",
        "Se puede realizar este ejemplo con CPU o GPU. En caso de ser con GPU es necesario indicarlo en los parámetros de configuración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.48 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (4.48.0)\n",
            "Requirement already satisfied: accelerate in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.4.0)\n",
            "Requirement already satisfied: sentencepiece in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (0.2.0)\n",
            "Requirement already satisfied: tokenizer in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (3.4.5)\n",
            "Requirement already satisfied: codecarbon in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.8.3)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (2024.11.6)\n",
            "Requirement already satisfied: requests in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (4.66.5)\n",
            "Requirement already satisfied: psutil in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from accelerate) (2.6.0)\n",
            "Requirement already satisfied: arrow in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (1.3.0)\n",
            "Requirement already satisfied: click in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (8.1.7)\n",
            "Requirement already satisfied: fief-client[cli] in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: pandas in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (1.3.5)\n",
            "Requirement already satisfied: prometheus-client in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (0.21.1)\n",
            "Requirement already satisfied: py-cpuinfo in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pynvml in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (12.0.0)\n",
            "Requirement already satisfied: questionary in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (2.1.0)\n",
            "Requirement already satisfied: rapidfuzz in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (3.12.1)\n",
            "Requirement already satisfied: rich in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (0.15.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48) (4.12.2)\n",
            "Requirement already satisfied: networkx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from arrow->codecarbon) (2.9.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from arrow->codecarbon) (2.9.0.20241206)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from fief-client[cli]->codecarbon) (3.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->codecarbon) (2024.2)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pynvml->codecarbon) (12.570.86)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from questionary->codecarbon) (3.0.47)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers==4.48) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers==4.48) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers==4.48) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers==4.48) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rich->codecarbon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rich->codecarbon) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.8.0)\n",
            "Requirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.14.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dash in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.18.2)\n",
            "Requirement already satisfied: dash-bootstrap-components in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.7.1)\n",
            "Requirement already satisfied: python-dotenv in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.0.1)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (3.0.4)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (6.0.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (5.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (2.32.3)\n",
            "Requirement already satisfied: retrying in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (75.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (1.8.2)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from plotly>=5.0.0->dash) (1.27.1)\n",
            "Requirement already satisfied: packaging in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from plotly>=5.0.0->dash) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from Werkzeug<3.1->dash) (2.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from importlib-metadata->dash) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->dash) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->dash) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->dash) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from retrying->dash) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers==4.48 accelerate sentencepiece tokenizer codecarbon -q\n",
        "%pip install dash dash-bootstrap-components python-dotenv -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Posiblemente, sea necesario reiniciar el kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739966605365
        },
        "id": "0LyAUyQ4s3_7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import pipeline\n",
        "import textwrap\n",
        "from codecarbon import EmissionsTracker\n",
        "from codecarbon import track_emissions\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parametros de configuración\n",
        "model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "project_name=\"worshop-ia-sostenible\"\n",
        "\n",
        "#TODO CAMBIAR RUTA DEL FICHERO\n",
        "#output_dir_emissions_track=\"/lakehouse/default/Files\"\n",
        "output_dir_emissions_track=\"/home/azureuser/cloudfiles/code/Users/paul.vanb/worshop-ia-sostenible/outputs\"\n",
        "output_file_emissions_track=f\"{project_name}_emissions.csv\"\n",
        "\n",
        "output_filename = os.path.join(output_dir_emissions_track,output_file_emissions_track )\n",
        "device_map=\"auto\"\n",
        "cloud_region=\"westus2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 17:38:09] Energy consumed for RAM : 0.000013 kWh. RAM Power : 3.092193603515625 W\n",
            "[codecarbon INFO @ 17:38:09] Energy consumed for all CPUs : 0.000407 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:38:09] 0.000419 kWh of electricity used since the beginning.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def wrap_text(text, width=100):\n",
        "    \"\"\"\n",
        "    Envuelve el texto dado para que cada línea no supere el ancho especificado.\n",
        "    \n",
        "    Args:\n",
        "        text (str): El texto de entrada.\n",
        "        width (int): El ancho máximo de cada línea (por defecto, 100 caracteres).\n",
        "    \n",
        "    Returns:\n",
        "        str: Texto con saltos de línea insertados para cumplir con el ancho especificado.\n",
        "    \"\"\"\n",
        "    lines = text.split('\\n')  # Divide el texto en líneas basadas en saltos de línea existentes.\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]  # Envuelve cada línea individualmente.\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)  # Une las líneas envueltas con saltos de línea.\n",
        "    return wrapped_text\n",
        "\n",
        "def generate(pipe, input_text, system_prompt=\"\", **generation_args):\n",
        "    \"\"\"\n",
        "    Genera una respuesta basada en el texto de entrada utilizando un modelo de IA.\n",
        "    \n",
        "    Args:\n",
        "        input_text (str): Texto de entrada del usuario.\n",
        "        system_prompt (str): Mensaje de sistema opcional para guiar la respuesta del modelo.\n",
        "        max_length (int): Longitud máxima de la respuesta generada (por defecto, 1024 caracteres).\n",
        "    \n",
        "    Returns:\n",
        "        str: Texto generado y formateado con saltos de línea adecuados.\n",
        "    \"\"\"\n",
        "    # Si no se proporciona un mensaje del sistema, se usa un mensaje por defecto.\n",
        "    if system_prompt != \"\":\n",
        "        system_prompt = system_prompt\n",
        "    else:\n",
        "        system_prompt = \"You are a friendly and helpful assistant\"\n",
        "    \n",
        "    # Construcción del historial de mensajes con el mensaje del sistema y la entrada del usuario.\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": input_text},\n",
        "    ]\n",
        "    \n",
        "    # Generación de la respuesta del modelo.\n",
        "    output = pipe(messages, **generation_args)\n",
        "    text = output[0]['generated_text']  # Obtiene el texto generado.\n",
        "    \n",
        "    # Envuelve el texto generado para cumplir con el ancho especificado.\n",
        "    wrapped_text = wrap_text(text)\n",
        "    return wrapped_text\n",
        "\n",
        "@track_emissions(project_name=\"workshop-sostenibilidad\", output_dir=output_dir_emissions_track,\n",
        "                 cloud_provider=\"azure\", cloud_region= cloud_region, pue=1.19)\n",
        "def answer_to_different_messages(pipe,messages):\n",
        "    \"\"\"\n",
        "    Procesa una lista de mensajes y genera respuestas mientras realiza un seguimiento de las emisiones.\n",
        "    \n",
        "    Args:\n",
        "        messages (list): Lista de mensajes de entrada.\n",
        "    \n",
        "    Returns:\n",
        "        list: Lista de respuestas generadas junto con los mensajes de entrada y sus identificadores.\n",
        "    \"\"\"\n",
        "    outputs = []  # Lista para almacenar los resultados.\n",
        "    system_prompt = \"Eres un asistente de Microsoft experto en sostenibilidad llamado SostAI\"  # Mensaje del sistema.\n",
        "    \n",
        "    # Itera sobre cada mensaje y genera una respuesta.\n",
        "    for mid, message in enumerate(messages):\n",
        "        output = generate(pipe, message, system_prompt=system_prompt)  # Genera la respuesta.\n",
        "        outputs.append([mid, message, output])  # Almacena el identificador, mensaje y respuesta.\n",
        "    \n",
        "    return outputs  # Devuelve la lista de respuestas generadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv2Oll0647jO"
      },
      "source": [
        "# Carga del Modelo\n",
        "Usaremos la librería transformers de Hugginface para cargar el modelo de microsoft Phi-3.5 mini instruído.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "0e980c20fece4573a9a522f1e5d84e00",
            "fcef54490bae4d83b6ef6d36bbf46d84",
            "1ed491b9ba624120bc6b3e6db5b98cf6",
            "102b824d816e43259751e828e46a2566",
            "51921656a92c437e82dc96a0d14246e3",
            "b715b9944fa547a4b65e554dc5d9fd1e",
            "11dec34858fe493ba356c42e98dec0c7",
            "7240007e78444219878b593e7b49a93a",
            "bd317caff4c8479fa02a4403361e2463",
            "2523f8c0d6274cdd977884b215f516a3",
            "fb068428db9148efbf737dbff9e01867"
          ]
        },
        "gather": {
          "logged": 1739965639405
        },
        "id": "4RQLYiQHtdJV",
        "outputId": "064a0a14-77ff-4b88-ab6a-45dd23c2da67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.79it/s]\n"
          ]
        }
      ],
      "source": [
        "torch.random.manual_seed(0)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map= device_map,\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "generation_args = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"return_full_text\": False,\n",
        "    \"temperature\": 0.0,\n",
        "    \"do_sample\": False,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH_iNESv5LjH"
      },
      "source": [
        "# Ejercicio 2\n",
        "Ahora vamos a hacer lo mismo que en el caso anterior, peri cambiando la región a brasil sur.\n",
        "Para identificar el nombre del centro de datos, usa: https://datacenters.microsoft.com/globe/explore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTK5TMmvtryP",
        "outputId": "3e488b30-0b67-4af7-c84f-7505c4ef1b29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 09:47:45] Codecarbon is taking the configuration from global file: /home/azureuser/.codecarbon.config\n",
            "[codecarbon INFO @ 09:47:45] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 09:47:45] [setup] CPU Tracking...\n",
            "[codecarbon DEBUG @ 09:47:45] Not using PowerGadget, an exception occurred while instantiating IntelPowerGadget : Platform not supported by Intel Power Gadget\n",
            "[codecarbon DEBUG @ 09:47:45] Not using the RAPL interface, an exception occurred while instantiating IntelRAPL : Intel RAPL files not found at /sys/class/powercap/intel-rapl on linux\n",
            "[codecarbon DEBUG @ 09:47:45] Not using PowerMetrics, an exception occurred while instantiating Powermetrics : Platform not supported by Powermetrics\n",
            "[codecarbon WARNING @ 09:47:45] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n",
            "[codecarbon DEBUG @ 09:47:46] CPU : We detect a Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz with a TDP of 195.0 W\n",
            "[codecarbon INFO @ 09:47:46] CPU Model on constant consumption mode: Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\n",
            "[codecarbon INFO @ 09:47:46] [setup] GPU Tracking...\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[codecarbon INFO @ 09:47:46] No GPU found.\n",
            "[codecarbon DEBUG @ 09:47:46] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: 3 Watts for 8 GB ratio constant\n",
            "                CPU Tracking Method: TDP constant\n",
            "                GPU Tracking Method: Unspecified\n",
            "            \n",
            "[codecarbon INFO @ 09:47:46] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 09:47:46]   Platform system: Linux-5.15.0-1073-azure-x86_64-with-glibc2.31\n",
            "[codecarbon INFO @ 09:47:46]   Python version: 3.10.14\n",
            "[codecarbon INFO @ 09:47:46]   CodeCarbon version: 2.8.3\n",
            "[codecarbon INFO @ 09:47:46]   Available RAM : 31.343 GB\n",
            "[codecarbon INFO @ 09:47:46]   CPU count: 4\n",
            "[codecarbon INFO @ 09:47:46]   CPU model: Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\n",
            "[codecarbon INFO @ 09:47:46]   GPU count: None\n",
            "[codecarbon INFO @ 09:47:46]   GPU model: None\n",
            "[codecarbon DEBUG @ 09:47:46] Not running on AWS\n",
            "[codecarbon WARNING @ 09:47:46] Cloud provider 'azure' do not publish electricity carbon intensity. Using country value instead.\n",
            "[codecarbon INFO @ 09:47:46] Saving emissions data to file /home/azureuser/cloudfiles/code/Users/paul.vanb/worshop-ia-sostenible/outputs/emissions.csv\n",
            "[codecarbon INFO @ 09:48:01] Energy consumed for RAM : 0.000013 kWh. RAM Power : 3.0619654655456543 W\n",
            "[codecarbon DEBUG @ 09:48:01] RAM : 3.06 W during 15.00 s [measurement time: 0.0087]\n",
            "[codecarbon INFO @ 09:48:01] Energy consumed for all CPUs : 0.000407 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon DEBUG @ 09:48:01] CPU : 97.50 W during 15.02 s [measurement time: 0.0011]\n",
            "[codecarbon INFO @ 09:48:01] 0.000420 kWh of electricity used since the beginning.\n",
            "[codecarbon DEBUG @ 09:48:01] last_duration=15.000936704000196\n",
            "------------------------\n",
            "[codecarbon DEBUG @ 09:48:15] Removing the lock\n",
            "[codecarbon INFO @ 09:48:15] Energy consumed for RAM : 0.000025 kWh. RAM Power : 3.061984062194824 W\n",
            "[codecarbon DEBUG @ 09:48:15] RAM : 3.06 W during 14.03 s [measurement time: 0.0047]\n",
            "[codecarbon INFO @ 09:48:15] Energy consumed for all CPUs : 0.000787 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon DEBUG @ 09:48:15] CPU : 97.50 W during 14.04 s [measurement time: 0.0006]\n",
            "[codecarbon INFO @ 09:48:15] 0.000812 kWh of electricity used since the beginning.\n",
            "[codecarbon DEBUG @ 09:48:15] last_duration=14.030080851000093\n",
            "------------------------\n",
            "[codecarbon DEBUG @ 09:48:15] EmissionsData(timestamp='2025-02-23T09:48:15', project_name='codecarbon', run_id='d50c6d8e-a5bd-46a7-8b1d-18e21a2c39b1', experiment_id='D08fa668-aed9-4ee9-a535-dedb1361039c', duration=29.065790291000667, emissions=6.879284537510763e-05, emissions_rate=2.3667976919384584e-06, cpu_power=97.5, gpu_power=0.0, ram_power=3.061984062194824, cpu_energy=0.0007870129882604299, gpu_energy=0, ram_energy=2.469230136785477e-05, energy_consumed=0.0008117052896282847, country_name='United States', country_iso_code='USA', region='washington', cloud_provider='', cloud_region='', os='Linux-5.15.0-1073-azure-x86_64-with-glibc2.31', python_version='3.10.14', codecarbon_version='2.8.3', cpu_count=4, cpu_model='Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz', gpu_count=None, gpu_model=None, longitude=-122.3303, latitude=47.6109, ram_total_size=31.343276977539062, tracking_mode='process', on_cloud='N', pue=1.0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 58.1 s, sys: 120 ms, total: 58.2 s\n",
            "Wall time: 35.2 s\n"
          ]
        }
      ],
      "source": [
        "#%%time\n",
        "# Start tracking\n",
        "tracker = EmissionsTracker(tracking_mode=\"process\",\n",
        "                           output_dir=output_dir_emissions_track) \n",
        "tracker.start()\n",
        "\n",
        "\n",
        "emmissions = tracker.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All hardware identified: [RAM(), CPU(Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz > 195.0W)]\n",
            "GPU/CPU Power: Power(kW=0.0975)\n",
            "Hardware zone: GeoMetadata(country_iso_code=USA, country_name=United States, region=washington)\n",
            "Emissions from this training run: 0.000069 kg CO2eq\n"
          ]
        }
      ],
      "source": [
        "print(f\"All hardware identified:{tracker._hardware}\")\n",
        "print(f\"GPU/CPU Power: {tracker._hardware[1].total_power()}\")\n",
        "print(f\"Hardware zone: {tracker._geo}\")\n",
        "print(f\"Emissions from this training run: {emmissions:5f} kg CO2eq\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicio 2 (opcional)\n",
        "Vamos a observar las diferencias en coste energético entre cpu y gpu, para eso vamos a ejecutar con una lista de 20 mensajes a tu elección, la función answer_to_different_messages con gpu y luego cpu.\n",
        "Para luego diferenciarlas en el output, asigna a la primera project_name \"phi-emissions-cpu\" y a la segunda \"phi-emissions-gpu\".\n",
        "Chequea en cada ejecución, que tracker._hardware es gpu y luego cpu. Tendrás que reiniciar el notebook.\n",
        "\n",
        "Observa los resultados y analizalos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e980c20fece4573a9a522f1e5d84e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcef54490bae4d83b6ef6d36bbf46d84",
              "IPY_MODEL_1ed491b9ba624120bc6b3e6db5b98cf6",
              "IPY_MODEL_102b824d816e43259751e828e46a2566"
            ],
            "layout": "IPY_MODEL_51921656a92c437e82dc96a0d14246e3"
          }
        },
        "102b824d816e43259751e828e46a2566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2523f8c0d6274cdd977884b215f516a3",
            "placeholder": "​",
            "style": "IPY_MODEL_fb068428db9148efbf737dbff9e01867",
            "value": " 2/2 [00:37&lt;00:00, 17.82s/it]"
          }
        },
        "11dec34858fe493ba356c42e98dec0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ed491b9ba624120bc6b3e6db5b98cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7240007e78444219878b593e7b49a93a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd317caff4c8479fa02a4403361e2463",
            "value": 2
          }
        },
        "2523f8c0d6274cdd977884b215f516a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51921656a92c437e82dc96a0d14246e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7240007e78444219878b593e7b49a93a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b715b9944fa547a4b65e554dc5d9fd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd317caff4c8479fa02a4403361e2463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb068428db9148efbf737dbff9e01867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcef54490bae4d83b6ef6d36bbf46d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b715b9944fa547a4b65e554dc5d9fd1e",
            "placeholder": "​",
            "style": "IPY_MODEL_11dec34858fe493ba356c42e98dec0c7",
            "value": "Loading checkpoint shards: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
