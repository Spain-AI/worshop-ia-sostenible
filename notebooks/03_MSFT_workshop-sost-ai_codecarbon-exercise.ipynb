{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2OJtDt541b3"
      },
      "source": [
        "# Workshop Microsoft - Sostenibilidad\n",
        "## Ejercicios\n",
        "A continuación haremos un ejercicio con codecarbon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.48 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (4.48.0)\n",
            "Requirement already satisfied: accelerate in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.4.0)\n",
            "Requirement already satisfied: sentencepiece in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (0.2.0)\n",
            "Requirement already satisfied: tokenizer in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (3.4.5)\n",
            "Requirement already satisfied: codecarbon in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.8.3)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (2024.11.6)\n",
            "Requirement already satisfied: requests in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers==4.48) (4.66.5)\n",
            "Requirement already satisfied: psutil in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from accelerate) (2.6.0)\n",
            "Requirement already satisfied: arrow in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (1.3.0)\n",
            "Requirement already satisfied: click in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (8.1.7)\n",
            "Requirement already satisfied: fief-client[cli] in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: pandas in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (1.3.5)\n",
            "Requirement already satisfied: prometheus-client in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (0.21.1)\n",
            "Requirement already satisfied: py-cpuinfo in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pynvml in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (12.0.0)\n",
            "Requirement already satisfied: questionary in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (2.1.0)\n",
            "Requirement already satisfied: rapidfuzz in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (3.12.1)\n",
            "Requirement already satisfied: rich in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from codecarbon) (0.15.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48) (4.12.2)\n",
            "Requirement already satisfied: networkx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from arrow->codecarbon) (2.9.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from arrow->codecarbon) (2.9.0.20241206)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from fief-client[cli]->codecarbon) (3.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->codecarbon) (2024.2)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pynvml->codecarbon) (12.570.86)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from questionary->codecarbon) (3.0.47)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers==4.48) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers==4.48) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers==4.48) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers==4.48) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rich->codecarbon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rich->codecarbon) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.8.0)\n",
            "Requirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.14.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dash in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.18.2)\n",
            "Requirement already satisfied: dash-bootstrap-components in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.7.1)\n",
            "Requirement already satisfied: python-dotenv in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.0.1)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (3.0.4)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (6.0.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (5.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (2.32.3)\n",
            "Requirement already satisfied: retrying in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dash) (75.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (1.8.2)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from plotly>=5.0.0->dash) (1.27.1)\n",
            "Requirement already satisfied: packaging in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from plotly>=5.0.0->dash) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from Werkzeug<3.1->dash) (2.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from importlib-metadata->dash) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->dash) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->dash) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->dash) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from retrying->dash) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers==4.48 accelerate sentencepiece tokenizer codecarbon -q \n",
        "%pip install dash dash-bootstrap-components python-dotenv -q\n",
        "%pip install flash_attn -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Posiblemente, sea necesario reiniciar el kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739966605365
        },
        "id": "0LyAUyQ4s3_7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import pipeline\n",
        "import textwrap\n",
        "from codecarbon import EmissionsTracker\n",
        "from codecarbon import track_emissions\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parametros de configuración\n",
        "model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "project_name=\"worshop-ia-sostenible-exercise\"\n",
        "\n",
        "#TODO CAMBIAR RUTA DEL FICHERO\n",
        "#output_dir_emissions_track=\"/lakehouse/default/Files\"\n",
        "output_dir_emissions_track=\"/home/azureuser/cloudfiles/code/Users/paul.vanb/worshop-ia-sostenible/outputs\"\n",
        "output_file_emissions_track=f\"{project_name}_emissions.csv\"\n",
        "\n",
        "output_filename = os.path.join(output_dir_emissions_track,output_file_emissions_track )\n",
        "device_map=\"auto\"\n",
        "cloud_region=\"westus2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 17:38:09] Energy consumed for RAM : 0.000013 kWh. RAM Power : 3.092193603515625 W\n",
            "[codecarbon INFO @ 17:38:09] Energy consumed for all CPUs : 0.000407 kWh. Total CPU Power : 97.5 W\n",
            "[codecarbon INFO @ 17:38:09] 0.000419 kWh of electricity used since the beginning.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def wrap_text(text, width=100):\n",
        "    \"\"\"\n",
        "    Envuelve el texto dado para que cada línea no supere el ancho especificado.\n",
        "    \n",
        "    Args:\n",
        "        text (str): El texto de entrada.\n",
        "        width (int): El ancho máximo de cada línea (por defecto, 100 caracteres).\n",
        "    \n",
        "    Returns:\n",
        "        str: Texto con saltos de línea insertados para cumplir con el ancho especificado.\n",
        "    \"\"\"\n",
        "    lines = text.split('\\n')  # Divide el texto en líneas basadas en saltos de línea existentes.\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]  # Envuelve cada línea individualmente.\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)  # Une las líneas envueltas con saltos de línea.\n",
        "    return wrapped_text\n",
        "\n",
        "def generate(pipe, input_text, system_prompt=\"\"):\n",
        "    \"\"\"\n",
        "    Genera una respuesta basada en el texto de entrada utilizando un modelo de IA.\n",
        "    \n",
        "    Args:\n",
        "        input_text (str): Texto de entrada del usuario.\n",
        "        system_prompt (str): Mensaje de sistema opcional para guiar la respuesta del modelo.\n",
        "        max_length (int): Longitud máxima de la respuesta generada (por defecto, 1024 caracteres).\n",
        "    \n",
        "    Returns:\n",
        "        str: Texto generado y formateado con saltos de línea adecuados.\n",
        "    \"\"\"\n",
        "    generation_args = {\n",
        "        \"max_new_tokens\": 500,\n",
        "        \"return_full_text\": False,\n",
        "        \"temperature\": 0.0,\n",
        "        \"do_sample\": False,\n",
        "    }\n",
        "    # Si no se proporciona un mensaje del sistema, se usa un mensaje por defecto.\n",
        "    if system_prompt != \"\":\n",
        "        system_prompt = system_prompt\n",
        "    else:\n",
        "        system_prompt = \"You are a friendly and helpful assistant\"\n",
        "    \n",
        "    # Construcción del historial de mensajes con el mensaje del sistema y la entrada del usuario.\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": input_text},\n",
        "    ]\n",
        "    \n",
        "    # Generación de la respuesta del modelo.\n",
        "    output = pipe(messages, **generation_args)\n",
        "    text = output[0]['generated_text']  # Obtiene el texto generado.\n",
        "    \n",
        "    # Envuelve el texto generado para cumplir con el ancho especificado.\n",
        "    wrapped_text = wrap_text(text)\n",
        "    return wrapped_text\n",
        "\n",
        "@track_emissions(project_name= project_name, output_dir=output_dir_emissions_track,\n",
        "                 cloud_provider=\"azure\", cloud_region= cloud_region, pue=1.19, output_file=output_file_emissions_track,\n",
        "                 allow_multiple_runs=True)\n",
        "def answer_to_different_messages(pipe,messages):\n",
        "    \"\"\"\n",
        "    Procesa una lista de mensajes y genera respuestas mientras realiza un seguimiento de las emisiones.\n",
        "    \n",
        "    Args:\n",
        "        messages (list): Lista de mensajes de entrada.\n",
        "    \n",
        "    Returns:\n",
        "        list: Lista de respuestas generadas junto con los mensajes de entrada y sus identificadores.\n",
        "    \"\"\"\n",
        "    outputs = []  # Lista para almacenar los resultados.\n",
        "    system_prompt = \"Eres un asistente de Microsoft experto en sostenibilidad llamado SostAI\"  # Mensaje del sistema.\n",
        "    \n",
        "    # Itera sobre cada mensaje y genera una respuesta.\n",
        "    for mid, message in enumerate(messages):\n",
        "        output = generate(pipe, message, system_prompt=system_prompt)  # Genera la respuesta.\n",
        "        outputs.append([mid, message, output])  # Almacena el identificador, mensaje y respuesta.\n",
        "    \n",
        "    return outputs  # Devuelve la lista de respuestas generadas.\n",
        "\n",
        "###############################################\n",
        "#################### PLOTS ####################\n",
        "###############################################\n",
        "\n",
        "def plot_stacked_power(df):\n",
        "    \"\"\"\n",
        "    Genera un gráfico de barras apiladas para visualizar el consumo de potencia (CPU, GPU, RAM) a lo largo del tiempo.\n",
        "    \n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame que contiene las columnas 'timestamp', 'cpu_power', 'gpu_power' y 'ram_power'.\n",
        "    \"\"\"\n",
        "    df_sorted = df.sort_values(by='timestamp')  # Ordenar por timestamp\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(df_sorted['timestamp'], df_sorted['cpu_power'], label='CPU Power', color='blue')\n",
        "    plt.bar(df_sorted['timestamp'], df_sorted['gpu_power'], bottom=df_sorted['cpu_power'], label='GPU Power', color='red')\n",
        "    plt.bar(df_sorted['timestamp'], df_sorted['ram_power'], bottom=df_sorted['cpu_power'] + df_sorted['gpu_power'], label='RAM Power', color='green')\n",
        "    \n",
        "    plt.xlabel('Timestamp')\n",
        "    plt.ylabel('Power Consumption (W)')\n",
        "    plt.title('Stacked Power Consumption Over Time')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_stacked_energy(df):\n",
        "    \"\"\"\n",
        "    Genera un gráfico de barras apiladas para visualizar el consumo de energía (CPU, GPU, RAM) a lo largo del tiempo.\n",
        "    \"\"\"\n",
        "    df_sorted = df.sort_values(by='timestamp')\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(df_sorted['timestamp'], df_sorted['cpu_energy'], label='CPU Energy', color='blue')\n",
        "    plt.bar(df_sorted['timestamp'], df_sorted['gpu_energy'], bottom=df_sorted['cpu_energy'], label='GPU Energy', color='red')\n",
        "    plt.bar(df_sorted['timestamp'], df_sorted['ram_energy'], bottom=df_sorted['cpu_energy'] + df_sorted['gpu_energy'], label='RAM Energy', color='green')\n",
        "    \n",
        "    # Agregar Total Energy Consumed como una barra al lado de cada apilamiento\n",
        "    bar_width = 0.28  # Definir el ancho de las barras\n",
        "    x_indexes = range(len(df_sorted['timestamp']))\n",
        "    plt.bar([x + bar_width for x in x_indexes], df_sorted['energy_consumed'], label='Total Energy Consumed', color='purple', alpha=0.7, width=bar_width)\n",
        "    \n",
        "    plt.xlabel('Timestamp')\n",
        "    plt.ylabel('Energy Consumption (kWh)')\n",
        "    plt.title('Stacked Energy Consumption Over Time')\n",
        "    plt.xticks([x + bar_width / 2 for x in x_indexes], df_sorted['timestamp'], rotation=45)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv2Oll0647jO"
      },
      "source": [
        "# Carga del Modelo\n",
        "Usaremos la librería transformers de Hugginface para cargar el modelo de microsoft Phi-3.5 mini instruído.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "0e980c20fece4573a9a522f1e5d84e00",
            "fcef54490bae4d83b6ef6d36bbf46d84",
            "1ed491b9ba624120bc6b3e6db5b98cf6",
            "102b824d816e43259751e828e46a2566",
            "51921656a92c437e82dc96a0d14246e3",
            "b715b9944fa547a4b65e554dc5d9fd1e",
            "11dec34858fe493ba356c42e98dec0c7",
            "7240007e78444219878b593e7b49a93a",
            "bd317caff4c8479fa02a4403361e2463",
            "2523f8c0d6274cdd977884b215f516a3",
            "fb068428db9148efbf737dbff9e01867"
          ]
        },
        "gather": {
          "logged": 1739965639405
        },
        "id": "4RQLYiQHtdJV",
        "outputId": "064a0a14-77ff-4b88-ab6a-45dd23c2da67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.79it/s]\n"
          ]
        }
      ],
      "source": [
        "torch.random.manual_seed(0)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map= device_map,\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "generation_args = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"return_full_text\": False,\n",
        "    \"temperature\": 0.0,\n",
        "    \"do_sample\": False,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH_iNESv5LjH"
      },
      "source": [
        "# Ejercicio 1\n",
        "Vamos a observar las diferencias en coste energético entre dos regiones diferentes para eso vamos a ejecutar con una lista mensajes definida, la función answer_to_different_messages para el país de brasil (country_code = BRA) y otra para la de Irlanda (country_code = IRL).\n",
        "Para luego diferenciarlas en el output, asigna a la primera project_name \"phi-emissions-bra\" y a la segunda \"phi-emissions-irl\".\n",
        "\n",
        "Para hacer esto, usaremos OfflineEmissionTracker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\"cuanto cuesta ser sostenible?\", \"Qué debo hacer para ser sostenible?\", \"Qué son los algoritmos verdes?\",\"Cuesta mucho ser eficiente?\",\n",
        "            \"Qué es la eficiencia energética?\"]\n",
        "print(len(messages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from codecarbon import OfflineEmissionsTracker\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicio 2 (opcional)\n",
        "Ahora vamos a observar las diferencias en coste energético entre cpu y gpu, para eso vamos a ejecutar con una lista de 20 mensajes a tu elección, la función answer_to_different_messages con gpu y luego cpu.\n",
        "Para luego diferenciarlas en el output, asigna a la primera project_name \"phi-emissions-cpu\" y a la segunda \"phi-emissions-gpu\".\n",
        "Chequea en cada ejecución, que tracker._hardware es gpu y luego cpu. Tendrás que reiniciar el notebook.\n",
        "\n",
        "Observa los resultados y analizalos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e980c20fece4573a9a522f1e5d84e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcef54490bae4d83b6ef6d36bbf46d84",
              "IPY_MODEL_1ed491b9ba624120bc6b3e6db5b98cf6",
              "IPY_MODEL_102b824d816e43259751e828e46a2566"
            ],
            "layout": "IPY_MODEL_51921656a92c437e82dc96a0d14246e3"
          }
        },
        "102b824d816e43259751e828e46a2566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2523f8c0d6274cdd977884b215f516a3",
            "placeholder": "​",
            "style": "IPY_MODEL_fb068428db9148efbf737dbff9e01867",
            "value": " 2/2 [00:37&lt;00:00, 17.82s/it]"
          }
        },
        "11dec34858fe493ba356c42e98dec0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ed491b9ba624120bc6b3e6db5b98cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7240007e78444219878b593e7b49a93a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd317caff4c8479fa02a4403361e2463",
            "value": 2
          }
        },
        "2523f8c0d6274cdd977884b215f516a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51921656a92c437e82dc96a0d14246e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7240007e78444219878b593e7b49a93a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b715b9944fa547a4b65e554dc5d9fd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd317caff4c8479fa02a4403361e2463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb068428db9148efbf737dbff9e01867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcef54490bae4d83b6ef6d36bbf46d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b715b9944fa547a4b65e554dc5d9fd1e",
            "placeholder": "​",
            "style": "IPY_MODEL_11dec34858fe493ba356c42e98dec0c7",
            "value": "Loading checkpoint shards: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
